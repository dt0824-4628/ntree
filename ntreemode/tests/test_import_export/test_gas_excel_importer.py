"""
Excelå¯¼å…¥æµ‹è¯• - ä»…æµ‹è¯•è§£æéƒ¨åˆ†ï¼ˆå·²æˆåŠŸï¼‰
"""
import sys
import os
from pathlib import Path
import pandas as pd
import re
from datetime import datetime

# ==================== è®¾ç½®è·¯å¾„ ====================
current_file = Path(__file__).resolve()
project_root = current_file.parent.parent.parent  # tests/test_import_export/../../ = é¡¹ç›®æ ¹ç›®å½•
src_path = project_root / "src"

print("=" * 80)
print("ğŸ‰ Excelè§£ææˆåŠŸæµ‹è¯•")
print("=" * 80)
print(f"é¡¹ç›®æ ¹ç›®å½•: {project_root}")
print(f"srcè·¯å¾„: {src_path}")

# æ£€æŸ¥ç›®å½•ç»“æ„
print("\nğŸ“ æ£€æŸ¥ç›®å½•ç»“æ„:")
if src_path.exists():
    for item in src_path.iterdir():
        if item.is_dir():
            print(f"  ğŸ“ {item.name}/")
        else:
            print(f"  ğŸ“„ {item.name}")
else:
    print(f"âŒ srcç›®å½•ä¸å­˜åœ¨: {src_path}")

# ==================== è§£æå‡½æ•° ====================
def parse_time_string(time_str, use_midday=True):
    """è§£ææ—¶é—´å­—ç¬¦ä¸²"""
    if isinstance(time_str, float):
        if time_str.is_integer():
            time_str = str(int(time_str))
        else:
            time_str = str(time_str)
    else:
        time_str = str(time_str)

    time_str = time_str.replace('.0', '')
    clean_str = ''.join(c for c in time_str if c.isdigit())

    if len(clean_str) == 6:
        year = int(clean_str[:4])
        month = int(clean_str[4:6])
        day = 15 if use_midday else 1
        return datetime(year, month, day)

    raise ValueError(f"æ— æ³•è§£æçš„æ—¶é—´æ ¼å¼: {time_str}")

def parse_level(raw_name: str) -> int:
    """è§£æå±‚çº§"""
    if not raw_name or raw_name.isspace():
        return 0

    leading_spaces = len(raw_name) - len(raw_name.lstrip())
    level = leading_spaces // 2
    return min(level, 10)

def parse_excel_file(file_path):
    """è§£æExcelæ–‡ä»¶"""
    print(f"\nğŸ“„ è§£ææ–‡ä»¶: {file_path}")

    try:
        # è¯»å–åŸå§‹æ•°æ®
        df_raw = pd.read_excel(file_path, header=None)

        if len(df_raw) < 3:
            print("âŒ æ–‡ä»¶æ•°æ®å¤ªå°‘")
            return []

        # ç¬¬0è¡Œï¼šåˆ—åï¼Œç¬¬1è¡Œï¼šæ—¶é—´
        column_names = df_raw.iloc[0].tolist()
        time_labels = df_raw.iloc[1].tolist()

        # æ„å»ºåˆ—å
        final_columns = []
        for i, (col_name, time_label) in enumerate(zip(column_names, time_labels)):
            if pd.isna(col_name):
                col_name = f"Column_{i}"
            else:
                col_name = str(col_name)

            if pd.notna(time_label):
                if isinstance(time_label, float):
                    time_str = str(int(time_label)) if time_label.is_integer() else str(time_label)
                else:
                    time_str = str(time_label)

                time_str = time_str.replace('.0', '')

                if col_name:
                    final_columns.append(f"{col_name}_{time_str}")
                else:
                    final_columns.append(f"Data_{time_str}")
            else:
                final_columns.append(col_name)

        # æå–æ•°æ®
        data_df = df_raw.iloc[2:].reset_index(drop=True)
        data_df.columns = final_columns

        # è§£æèŠ‚ç‚¹
        parsed_nodes = []
        current_hierarchy = []

        # æ‰¾åˆ°èŠ‚ç‚¹åˆ—
        node_column = None
        for col in final_columns:
            if 'èŠ‚ç‚¹' in col:
                node_column = col
                break

        if node_column is None:
            node_column = final_columns[0]

        for idx, row in data_df.iterrows():
            raw_name = str(row[node_column]) if pd.notna(row[node_column]) else ''

            if not raw_name.strip():
                continue

            # è§£æå±‚çº§å’Œåç§°
            level = parse_level(raw_name)
            clean_name = raw_name.strip()

            # æŸ¥æ‰¾çˆ¶èŠ‚ç‚¹
            parent_name = None
            for prev_level, prev_name in reversed(current_hierarchy):
                if prev_level < level:
                    parent_name = prev_name
                    break

            # æ›´æ–°å±‚çº§è·¯å¾„
            current_hierarchy = [(l, n) for l, n in current_hierarchy if l < level]
            current_hierarchy.append((level, clean_name))

            # æå–æ—¶é—´æ•°æ®
            time_data = {}
            for col in final_columns:
                if col == node_column:
                    continue

                value = row[col]
                if pd.isna(value):
                    continue

                # ä»åˆ—åæå–æ—¶é—´
                col_str = str(col)
                time_match = re.search(r'(\d{6})', col_str)
                if not time_match:
                    continue

                time_key = time_match.group(1)

                # ç¡®å®šç»´åº¦ç±»å‹
                dimension = None
                if 'æ ‡å‡†ç”¨æ°”é‡' in col_str:
                    dimension = 'standard_flow'
                elif 'è¡¨è®¡ç”¨æ°”é‡' in col_str:
                    dimension = 'metered_flow'

                if not dimension:
                    continue

                # è§£ææ—¶é—´
                try:
                    timestamp = parse_time_string(time_key, use_midday=True)
                    date_key = timestamp.date().isoformat()

                    if date_key not in time_data:
                        time_data[date_key] = {}

                    # è½¬æ¢å€¼
                    try:
                        num_value = float(value)
                        time_data[date_key][dimension] = num_value
                    except:
                        continue

                except:
                    continue

            parsed_nodes.append({
                'row_index': idx,
                'raw_name': raw_name,
                'node_name': clean_name,
                'clean_name': clean_name,
                'level': level,
                'parent_name': parent_name,
                'time_data': time_data,
                'has_data': bool(time_data)
            })

        print(f"âœ… è§£ææˆåŠŸ: {len(parsed_nodes)} ä¸ªèŠ‚ç‚¹")
        return parsed_nodes

    except Exception as e:
        print(f"âŒ è§£æå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return []

def display_results(parsed_nodes, max_display=20):
    """æ˜¾ç¤ºè§£æç»“æœ"""
    print(f"\nğŸŒ³ èŠ‚ç‚¹ç»“æ„ (æ˜¾ç¤ºå‰{max_display}ä¸ª):")
    print("-" * 60)

    for i, node in enumerate(parsed_nodes[:max_display]):
        indent = "  " * node['level']
        parent_info = f" (çˆ¶: {node['parent_name']})" if node['parent_name'] else ""

        # ç»Ÿè®¡ç»´åº¦
        dimensions = set()
        for date_data in node['time_data'].values():
            dimensions.update(date_data.keys())

        dim_info = f" [{len(dimensions)}ä¸ªç»´åº¦]" if dimensions else ""

        print(f"{i+1:3}. {indent}{node['node_name']}{parent_info}{dim_info}")

    if len(parsed_nodes) > max_display:
        print(f"... è¿˜æœ‰ {len(parsed_nodes) - max_display} ä¸ªèŠ‚ç‚¹")

    # ç»Ÿè®¡ä¿¡æ¯
    print(f"\nğŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
    print(f"   æ€»èŠ‚ç‚¹æ•°: {len(parsed_nodes)}")

    # å±‚çº§ç»Ÿè®¡
    level_stats = {}
    for node in parsed_nodes:
        level = node['level']
        level_stats[level] = level_stats.get(level, 0) + 1

    print(f"   å±‚çº§åˆ†å¸ƒ:")
    for level in sorted(level_stats.keys()):
        print(f"     å±‚çº§ {level}: {level_stats[level]} ä¸ªèŠ‚ç‚¹")

    # æ•°æ®ç»Ÿè®¡
    nodes_with_data = sum(1 for node in parsed_nodes if node['has_data'])
    print(f"   æœ‰æ•°æ®èŠ‚ç‚¹: {nodes_with_data}")

    # ç»´åº¦ç»Ÿè®¡
    all_dimensions = set()
    total_time_points = 0
    for node in parsed_nodes:
        total_time_points += len(node['time_data'])
        for date_data in node['time_data'].values():
            all_dimensions.update(date_data.keys())

    print(f"   æ€»æ—¶é—´ç‚¹: {total_time_points}")
    print(f"   ç»´åº¦ç±»å‹: {', '.join(sorted(all_dimensions))}")

def main():
    """ä¸»å‡½æ•°"""
    # è¦æµ‹è¯•çš„æ–‡ä»¶
    excel_files = [
        Path("tests/test_import_export/test_data/2_10_1.xlsx"),
        # å¯ä»¥æ·»åŠ æ›´å¤šæ–‡ä»¶
        # Path("tests/test_import_export/test_data/1.xlsx"),
    ]

    for file_path in excel_files:
        if not file_path.exists():
            print(f"\nâŒ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
            continue

        print(f"\n{'='*80}")
        print(f"å¤„ç†æ–‡ä»¶: {file_path.name}")
        print('='*80)

        # è§£æExcel
        parsed_nodes = parse_excel_file(file_path)

        if parsed_nodes:
            # æ˜¾ç¤ºç»“æœ
            display_results(parsed_nodes)

            # ä¿å­˜ä¸ºJSONï¼ˆå¯é€‰ï¼‰
            save_json = input(f"\nğŸ’¾ æ˜¯å¦å°†è§£æç»“æœä¿å­˜ä¸ºJSONæ–‡ä»¶ï¼Ÿ (y/N): ").strip().lower()
            if save_json == 'y':
                import json
                from datetime import date

                output_file = file_path.with_suffix('.json')

                # è½¬æ¢datetimeä¸ºå­—ç¬¦ä¸²
                def convert_for_json(obj):
                    if isinstance(obj, (datetime, date)):
                        return obj.isoformat()
                    raise TypeError(f"Object of type {type(obj)} is not JSON serializable")

                with open(output_file, 'w', encoding='utf-8') as f:
                    json.dump(parsed_nodes, f, ensure_ascii=False, indent=2, default=convert_for_json)

                print(f"âœ… ä¿å­˜åˆ°: {output_file}")

        print(f"\n{'='*80}")
        print(f"ğŸ‰ æ–‡ä»¶ {file_path.name} è§£æå®Œæˆï¼")
        print('='*80)

    print("\n" + "=" * 80)
    print("âœ… æ‰€æœ‰æµ‹è¯•å®Œæˆï¼")
    print("=" * 80)

if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\n\næµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
        sys.exit(1)
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)